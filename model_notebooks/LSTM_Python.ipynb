{"cells":[{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700277487004,"execution_millis":8,"deepnote_to_be_reexecuted":false,"cell_id":"831bff236a8d47ac83c948c4c2243368","deepnote_cell_type":"code"},"source":"import pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM","block_group":"831bff236a8d47ac83c948c4c2243368","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700277489483,"execution_millis":6,"deepnote_to_be_reexecuted":false,"cell_id":"3bf3067aedb0405dbdbb4250ac117552","deepnote_cell_type":"code"},"source":"from tensorflow import keras","block_group":"3aab1ff9fa584ec6bec7e7b434e7329e","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"78253f7129434dd9a8731aadb89dc082","deepnote_cell_type":"text-cell-h1"},"source":"# LSTM Proof of Concept","block_group":"0f5c2ca30d404a1388e060ca7354ecbf"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"92c114f8c5174dfd84c985681e2676e8","deepnote_cell_type":"text-cell-p"},"source":"Before we jump straight into using LSTMs to help us handle real-time 5-minute prediction, let's try getting the bare-bones of the model running!","block_group":"dbeeb4ac3bc54dc69ff4c2bb4a891cf1"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"52b69f417be345bf8b9731350cee3f6b","deepnote_cell_type":"text-cell-p"},"source":"To do this, we will first utilize hourly aggregate data, so that we're not giving DeepNote a complete meltdown.","block_group":"00eb33db0ad049b585e9a7d63c057951"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700277492510,"execution_millis":2631,"deepnote_to_be_reexecuted":false,"cell_id":"60b2baf5618341cba3fc52814bd5ada4","deepnote_cell_type":"code"},"source":"raw_data = pd.read_csv(\"/work/CAISO_data.csv\")","block_group":"bec6f46e7e4c433189b76b0443bbfd42","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700278515669,"execution_millis":511,"deepnote_to_be_reexecuted":false,"cell_id":"5766fe1b03c94be3a2486d25c349de33","deepnote_cell_type":"code"},"source":"data = raw_data.copy()\ndata['timestamp'] = pd.to_datetime(data['timestamp'])\ndata = data.set_index('timestamp') # Next line requires DateTimeIndex to function properly\ndata = data.resample('H').sum() # This functions like a groupby statement on hour\n\n# Sort by time for readability\ndata = data.reset_index().sort_values('timestamp', ascending=True).set_index('timestamp') \ndata.head()","block_group":"10e0d134460f411495a51537141744f2","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":2,"row_count":5,"columns":[{"name":"Unnamed: 0","dtype":"int64","stats":{"unique_count":5,"nan_count":0,"min":"1314","max":"1791","histogram":[{"bin_start":1314,"bin_end":1361.7,"count":1},{"bin_start":1361.7,"bin_end":1409.4,"count":1},{"bin_start":1409.4,"bin_end":1457.1,"count":0},{"bin_start":1457.1,"bin_end":1504.8,"count":0},{"bin_start":1504.8,"bin_end":1552.5,"count":0},{"bin_start":1552.5,"bin_end":1600.2,"count":1},{"bin_start":1600.2,"bin_end":1647.9,"count":0},{"bin_start":1647.9,"bin_end":1695.6,"count":0},{"bin_start":1695.6,"bin_end":1743.3,"count":0},{"bin_start":1743.3,"bin_end":1791,"count":2}]}},{"name":"load_MW","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"247700.0","max":"269994.0","histogram":[{"bin_start":247700,"bin_end":249929.4,"count":2},{"bin_start":249929.4,"bin_end":252158.8,"count":0},{"bin_start":252158.8,"bin_end":254388.2,"count":1},{"bin_start":254388.2,"bin_end":256617.6,"count":0},{"bin_start":256617.6,"bin_end":258847,"count":0},{"bin_start":258847,"bin_end":261076.4,"count":1},{"bin_start":261076.4,"bin_end":263305.8,"count":0},{"bin_start":263305.8,"bin_end":265535.2,"count":0},{"bin_start":265535.2,"bin_end":267764.6,"count":0},{"bin_start":267764.6,"bin_end":269994,"count":1}]}},{"name":"_deepnote_index_column","dtype":"datetime64[ns, UTC]"}],"rows":[{"Unnamed: 0":1377,"load_MW":269994,"_deepnote_index_column":"2015-01-01 08:00:00+00:00"},{"Unnamed: 0":1765,"load_MW":259722,"_deepnote_index_column":"2015-01-01 09:00:00+00:00"},{"Unnamed: 0":1314,"load_MW":252780,"_deepnote_index_column":"2015-01-01 10:00:00+00:00"},{"Unnamed: 0":1791,"load_MW":247985,"_deepnote_index_column":"2015-01-01 11:00:00+00:00"},{"Unnamed: 0":1580,"load_MW":247700,"_deepnote_index_column":"2015-01-01 12:00:00+00:00"}]},"text/plain":"                           Unnamed: 0   load_MW\ntimestamp                                      \n2015-01-01 08:00:00+00:00        1377  269994.0\n2015-01-01 09:00:00+00:00        1765  259722.0\n2015-01-01 10:00:00+00:00        1314  252780.0\n2015-01-01 11:00:00+00:00        1791  247985.0\n2015-01-01 12:00:00+00:00        1580  247700.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>load_MW</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-01 08:00:00+00:00</th>\n      <td>1377</td>\n      <td>269994.0</td>\n    </tr>\n    <tr>\n      <th>2015-01-01 09:00:00+00:00</th>\n      <td>1765</td>\n      <td>259722.0</td>\n    </tr>\n    <tr>\n      <th>2015-01-01 10:00:00+00:00</th>\n      <td>1314</td>\n      <td>252780.0</td>\n    </tr>\n    <tr>\n      <th>2015-01-01 11:00:00+00:00</th>\n      <td>1791</td>\n      <td>247985.0</td>\n    </tr>\n    <tr>\n      <th>2015-01-01 12:00:00+00:00</th>\n      <td>1580</td>\n      <td>247700.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700278516424,"execution_millis":12,"deepnote_to_be_reexecuted":false,"cell_id":"e0875ddc4b0e4bcc9fac2fb108e60b7d","deepnote_cell_type":"code"},"source":"len(data)","block_group":"672fd7e654d24f2db7a8f622cfe5dc48","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"70128"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700279143230,"execution_millis":20,"deepnote_to_be_reexecuted":false,"cell_id":"9809e49addfc4d36b444ccf6cd464e61","deepnote_cell_type":"code"},"source":"# Convert data to proper format for training\ndef create_dataset(dataset, look_back=1):\n    \"\"\"\n    Returns two numpy arrays corresponding to the \n    features to train on and their corresponding labels, respectively.\n\n    Inputs:\n        dataset: raw training data with time as index and rows as electricity demand\n        look_back: how far back we would like our model to look back to make the next prediction\n    \"\"\"\n    X, Y = [], []\n    for i in range(len(dataset) - look_back - 1):\n        a = dataset[i:(i + look_back), 0]\n        X.append(a)\n        Y.append(dataset[i + look_back, 0])\n    return np.array(X), np.array(Y)\n\nlook_back = 8  # Number of previous hours to consider\nX, Y = create_dataset(data['load_MW'].to_numpy().reshape([len(data), 1]), look_back)\n\n# There are some NaNs in our data, removing them for simplicity\nunclean_dataset = pd.DataFrame(X)\nunclean_dataset['y'] = Y\nclean_dataset = unclean_dataset[unclean_dataset.isna().sum(axis=1) == 0]\n\n# ...like there were never any NaNs to begin with :D\nY = clean_dataset['y'].to_numpy()\nX = clean_dataset.drop('y', axis=1).to_numpy()\n\n# Splitting the dataset into Training and Test sets\ntrain_size = int(len(X) * 0.8)\ntest_size = len(X) - train_size\ntrain_X, test_X = X[0:train_size], X[train_size:len(X)]\ntrain_Y, test_Y = Y[0:train_size], Y[train_size:len(Y)]","block_group":"b5343038925a4a6baaa98fc713ed6fed","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700279179234,"execution_millis":206,"deepnote_to_be_reexecuted":false,"cell_id":"d448f3e6eee64069b209e0624baf1aaf","deepnote_cell_type":"code"},"source":"# Reshape input to be [samples, time steps, features]\ntrain_X = train_X.reshape((train_X.shape[0], train_X.shape[1], 1))\ntest_X = test_X.reshape((test_X.shape[0], test_X.shape[1], 1))\n\nkeras.backend.clear_session()\n# Create and fit the LSTM network\nmodel3 = keras.Sequential()\nmodel3.add(keras.Input(shape=(look_back, 1)))\nmodel3.add(LSTM(100, input_shape=(look_back, 1)))\nmodel3.add(Dense(10, activation='relu'))\nmodel3.add(Dense(1))\nmodel3.compile(loss='mean_squared_error', optimizer='sgd')","block_group":"22b749f477ff4712b96d51e5d6805ead","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700279180109,"execution_millis":13551,"deepnote_to_be_reexecuted":false,"cell_id":"9a0cddf83ea04038a56a00acc8217922","deepnote_cell_type":"code"},"source":"# Proof of concept: checking to see if the model errors or yields erroneous results\nmodel3.fit(train_X[:250, :, :], train_Y[:250], epochs=1000, batch_size=32, verbose=1)","block_group":"19adaf1ae69444d99d45fe44c19b9951","execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/1000\n8/8 [==============================] - 1s 12ms/step - loss: 59653848746164224.0000\nEpoch 2/1000\n8/8 [==============================] - 0s 4ms/step - loss: 132853799059456.0000\nEpoch 3/1000\n8/8 [==============================] - 0s 4ms/step - loss: 96160517718016.0000\nEpoch 4/1000\n8/8 [==============================] - 0s 13ms/step - loss: 69602126069760.0000\nEpoch 5/1000\n8/8 [==============================] - 0s 12ms/step - loss: 50378326409216.0000\nEpoch 6/1000\n8/8 [==============================] - 0s 13ms/step - loss: 36463735472128.0000\nEpoch 7/1000\n8/8 [==============================] - 0s 12ms/step - loss: 26392901189632.0000\nEpoch 8/1000\n8/8 [==============================] - 0s 4ms/step - loss: 19103494438912.0000\nEpoch 9/1000\n8/8 [==============================] - 0s 4ms/step - loss: 13827569614848.0000\nEpoch 10/1000\n8/8 [==============================] - 0s 13ms/step - loss: 10008689377280.0000\nEpoch 11/1000\n8/8 [==============================] - 0s 12ms/step - loss: 7244507250688.0000\nEpoch 12/1000\n8/8 [==============================] - 0s 12ms/step - loss: 5243689500672.0000\nEpoch 13/1000\n8/8 [==============================] - 0s 13ms/step - loss: 3795353075712.0000\nEpoch 14/1000\n8/8 [==============================] - 0s 12ms/step - loss: 2747264139264.0000\nEpoch 15/1000\n8/8 [==============================] - 0s 5ms/step - loss: 1988732518400.0000\nEpoch 16/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1439778078720.0000\nEpoch 17/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1042439274496.0000\nEpoch 18/1000\n8/8 [==============================] - 0s 13ms/step - loss: 754846793728.0000\nEpoch 19/1000\n8/8 [==============================] - 0s 12ms/step - loss: 546626797568.0000\nEpoch 20/1000\n8/8 [==============================] - 0s 13ms/step - loss: 395968839680.0000\nEpoch 21/1000\n8/8 [==============================] - 0s 12ms/step - loss: 286952849408.0000\nEpoch 22/1000\n8/8 [==============================] - 0s 4ms/step - loss: 208053387264.0000\nEpoch 23/1000\n8/8 [==============================] - 0s 5ms/step - loss: 150953410560.0000\nEpoch 24/1000\n8/8 [==============================] - 0s 11ms/step - loss: 109594722304.0000\nEpoch 25/1000\n8/8 [==============================] - 0s 12ms/step - loss: 79654977536.0000\nEpoch 26/1000\n8/8 [==============================] - 0s 12ms/step - loss: 57990000640.0000\nEpoch 27/1000\n8/8 [==============================] - 0s 12ms/step - loss: 42301636608.0000\nEpoch 28/1000\n8/8 [==============================] - 0s 12ms/step - loss: 30957559808.0000\nEpoch 29/1000\n8/8 [==============================] - 0s 4ms/step - loss: 22768513024.0000\nEpoch 30/1000\n8/8 [==============================] - 0s 12ms/step - loss: 16819844096.0000\nEpoch 31/1000\n8/8 [==============================] - 0s 12ms/step - loss: 12517304320.0000\nEpoch 32/1000\n8/8 [==============================] - 0s 13ms/step - loss: 9400024064.0000\nEpoch 33/1000\n8/8 [==============================] - 0s 12ms/step - loss: 7152877056.0000\nEpoch 34/1000\n8/8 [==============================] - 0s 12ms/step - loss: 5513480192.0000\nEpoch 35/1000\n8/8 [==============================] - 0s 5ms/step - loss: 4336487424.0000\nEpoch 36/1000\n8/8 [==============================] - 0s 4ms/step - loss: 3482214912.0000\nEpoch 37/1000\n8/8 [==============================] - 0s 12ms/step - loss: 2859937024.0000\nEpoch 38/1000\n8/8 [==============================] - 0s 11ms/step - loss: 2412423680.0000\nEpoch 39/1000\n8/8 [==============================] - 0s 14ms/step - loss: 2089014016.0000\nEpoch 40/1000\n8/8 [==============================] - 0s 10ms/step - loss: 1855406976.0000\nEpoch 41/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1685560192.0000\nEpoch 42/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1562923520.0000\nEpoch 43/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1473072256.0000\nEpoch 44/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1407287552.0000\nEpoch 45/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1359856768.0000\nEpoch 46/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1326413696.0000\nEpoch 47/1000\n8/8 [==============================] - 0s 6ms/step - loss: 1301307648.0000\nEpoch 48/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1283459072.0000\nEpoch 49/1000\n8/8 [==============================] - 0s 5ms/step - loss: 1270515456.0000\nEpoch 50/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1262057600.0000\nEpoch 51/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1255479552.0000\nEpoch 52/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1250789632.0000\nEpoch 53/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1246658816.0000\nEpoch 54/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1244653568.0000\nEpoch 55/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1242890368.0000\nEpoch 56/1000\n8/8 [==============================] - 0s 5ms/step - loss: 1241403648.0000\nEpoch 57/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1241024128.0000\nEpoch 58/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1239953152.0000\nEpoch 59/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1238926976.0000\nEpoch 60/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238580736.0000\nEpoch 61/1000\n8/8 [==============================] - 0s 5ms/step - loss: 1238874880.0000\nEpoch 62/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1239041536.0000\nEpoch 63/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1238680320.0000\nEpoch 64/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1237991680.0000\nEpoch 65/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1238955776.0000\nEpoch 66/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238113408.0000\nEpoch 67/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1237653504.0000\nEpoch 68/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238133888.0000\nEpoch 69/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238440192.0000\nEpoch 70/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238059264.0000\nEpoch 71/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237803648.0000\nEpoch 72/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1237987584.0000\nEpoch 73/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238408448.0000\nEpoch 74/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1237821312.0000\nEpoch 75/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1238017280.0000\nEpoch 76/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1237873920.0000\nEpoch 77/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237779712.0000\nEpoch 78/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238171136.0000\nEpoch 79/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238064768.0000\nEpoch 80/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238051584.0000\nEpoch 81/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238239744.0000\nEpoch 82/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238065920.0000\nEpoch 83/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237709568.0000\nEpoch 84/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237915648.0000\nEpoch 85/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1237440512.0000\nEpoch 86/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238136064.0000\nEpoch 87/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238116864.0000\nEpoch 88/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1237906560.0000\nEpoch 89/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1238182528.0000\nEpoch 90/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238396928.0000\nEpoch 91/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238511232.0000\nEpoch 92/1000\n8/8 [==============================] - 0s 5ms/step - loss: 1238566272.0000\nEpoch 93/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238320896.0000\nEpoch 94/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237833600.0000\nEpoch 95/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238180096.0000\nEpoch 96/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237898624.0000\nEpoch 97/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238820480.0000\nEpoch 98/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238774528.0000\nEpoch 99/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1237599104.0000\nEpoch 100/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1237964544.0000\nEpoch 101/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237674240.0000\nEpoch 102/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238111360.0000\nEpoch 103/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1238147840.0000\nEpoch 104/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238386688.0000\nEpoch 105/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1237721600.0000\nEpoch 106/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238805248.0000\nEpoch 107/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1238369280.0000\nEpoch 108/1000\n8/8 [==============================] - 0s 11ms/step - loss: 1238271360.0000\nEpoch 109/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237596416.0000\nEpoch 110/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237862144.0000\nEpoch 111/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238439424.0000\nEpoch 112/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1237606144.0000\nEpoch 113/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237665536.0000\nEpoch 114/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1237647488.0000\nEpoch 115/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237859328.0000\nEpoch 116/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238153856.0000\nEpoch 117/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238024960.0000\nEpoch 118/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1237858944.0000\nEpoch 119/1000\n8/8 [==============================] - 0s 11ms/step - loss: 1237907456.0000\nEpoch 120/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238252416.0000\nEpoch 121/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238652160.0000\nEpoch 122/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237764864.0000\nEpoch 123/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1237639552.0000\nEpoch 124/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1238264192.0000\nEpoch 125/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237956096.0000\nEpoch 126/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1237551232.0000\nEpoch 127/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238332672.0000\nEpoch 128/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1238196736.0000\nEpoch 129/1000\n8/8 [==============================] - 0s 5ms/step - loss: 1237953664.0000\nEpoch 130/1000\n8/8 [==============================] - 0s 4ms/step - loss: 1237540352.0000\nEpoch 131/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237726464.0000\nEpoch 132/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1237826304.0000\nEpoch 133/1000\n8/8 [==============================] - 0s 13ms/step - loss: 1238206464.0000\nEpoch 134/1000\n8/8 [==============================] - 0s 11ms/step - loss: 1237654528.0000\nEpoch 135/1000\n8/8 [==============================] - 0s 5ms/step - loss: 1237839488.0000\nEpoch 136/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238133760.0000\nEpoch 137/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1237920640.0000\nEpoch 138/1000\n8/8 [==============================] - 0s 9ms/step - loss: 1238162304.0000\nEpoch 139/1000\n8/8 [==============================] - 0s 6ms/step - loss: 1238843520.0000\nEpoch 140/1000\n8/8 [==============================] - 0s 10ms/step - loss: 1237944192.0000\nEpoch 141/1000\n8/8 [==============================] - 0s 12ms/step - loss: 1238378496.0000\nEpoch 142/1000\n8/8 [==============================] - 0s 11ms/step - loss: 1238328832.0000\nEpoch 143/1000\n1/8 [==>...........................] - ETA: 0s - loss: 1686776064.0000","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Proof of concept: checking to see if the model errors or yields erroneous results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2495\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m-> 2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2719\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2716\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2718\u001b[0m \u001b[38;5;66;03m# Get runtime values of captures\u001b[39;00m\n\u001b[0;32m-> 2719\u001b[0m captures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_captures_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_snapshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2721\u001b[0m \u001b[38;5;66;03m# cache_key_deletion_observer is useless here. It's based on all captures.\u001b[39;00m\n\u001b[1;32m   2722\u001b[0m \u001b[38;5;66;03m# A new cache key will be built later when saving ConcreteFunction because\u001b[39;00m\n\u001b[1;32m   2723\u001b[0m \u001b[38;5;66;03m# only active captures should be saved.\u001b[39;00m\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:155\u001b[0m, in \u001b[0;36mCapturesContainer.get_snapshot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_captures:\n\u001b[1;32m    153\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_captures[key] \u001b[38;5;241m=\u001b[39m func\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_snapshot\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[Hashable, Any]:\n\u001b[1;32m    156\u001b[0m   snapshot \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    157\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m key, func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptures\u001b[38;5;241m.\u001b[39mitems():\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700279085120,"execution_millis":26,"deepnote_to_be_reexecuted":false,"cell_id":"0aa37e0bada64b0ea0b2488b36e0710f","deepnote_cell_type":"code"},"source":"# np.sqrt(model3.history.history['loss'])","block_group":"f30c31acf8e94cfcb286b9d6747ccf5c","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700278370589,"execution_millis":8,"deepnote_to_be_reexecuted":false,"cell_id":"943699ddc7134749ba17ba9b2087221b","deepnote_cell_type":"code"},"source":"# RMSE from running one epoch\nnp.sqrt(model3.history.history['loss'])","block_group":"ac85050c94c24a09830fe640befabf23","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"array([1.37364223e+06, 1.34616937e+06, 1.31924602e+06, 1.29286098e+06,\n       1.26700387e+06, 1.24166376e+06, 1.21683050e+06, 1.19249400e+06,\n       1.16864401e+06, 1.14527127e+06, 1.12236572e+06, 1.09991847e+06,\n       1.07791997e+06, 1.05636172e+06, 1.03523444e+06, 1.01452974e+06,\n       9.94239141e+05, 9.74354362e+05, 9.54867303e+05, 9.35769928e+05,\n       9.17054568e+05, 8.98713514e+05, 8.80739232e+05, 8.63124454e+05,\n       8.45861927e+05, 8.28944682e+05, 8.12365813e+05, 7.96118512e+05,\n       7.80196110e+05, 7.64592205e+05, 7.49300368e+05, 7.34314369e+05,\n       7.19628067e+05, 7.05235489e+05, 6.91130758e+05, 6.77308127e+05,\n       6.63761991e+05, 6.50486756e+05, 6.37477011e+05, 6.24727496e+05,\n       6.12232871e+05, 5.99988255e+05, 5.87988505e+05, 5.76228762e+05,\n       5.64704115e+05, 5.53410069e+05, 5.42341876e+05, 5.31494997e+05,\n       5.20865124e+05, 5.10447807e+05, 5.00238870e+05, 4.90234101e+05,\n       4.80429410e+05, 4.70820819e+05, 4.61404368e+05, 4.52176319e+05,\n       4.43132746e+05, 4.34270122e+05, 4.25584678e+05, 4.17073009e+05,\n       4.08731559e+05, 4.00556935e+05, 3.92545804e+05, 3.84694881e+05,\n       3.77001006e+05, 3.69460964e+05, 3.62071752e+05, 3.54830314e+05,\n       3.47733692e+05, 3.40779033e+05, 3.33963443e+05, 3.27284186e+05,\n       3.20738501e+05, 3.14323723e+05, 3.08037246e+05, 3.01876501e+05,\n       2.95838974e+05, 2.89922190e+05, 2.84123745e+05, 2.78441281e+05,\n       2.72872434e+05, 2.67415007e+05, 2.62066700e+05, 2.56825373e+05,\n       2.51688859e+05, 2.46655095e+05, 2.41721985e+05, 2.36887543e+05,\n       2.32149800e+05, 2.27506795e+05, 2.22956656e+05, 2.18497528e+05,\n       2.14127579e+05, 2.09845031e+05, 2.05648124e+05, 2.01535157e+05,\n       1.97504467e+05, 1.93554380e+05, 1.89683282e+05, 1.85889628e+05,\n       1.82171826e+05, 1.78528393e+05, 1.74957810e+05, 1.71458658e+05,\n       1.68029498e+05, 1.64668903e+05, 1.61375534e+05, 1.58148034e+05,\n       1.54985062e+05, 1.51885356e+05, 1.48847655e+05, 1.45870700e+05,\n       1.42953280e+05, 1.40094217e+05, 1.37292344e+05, 1.34546503e+05,\n       1.31855564e+05, 1.29218461e+05, 1.26634092e+05, 1.24101405e+05,\n       1.21619375e+05, 1.19186985e+05, 1.16803248e+05, 1.14467189e+05,\n       1.12177843e+05, 1.09934280e+05, 1.07735593e+05, 1.05580876e+05,\n       1.03469248e+05, 1.01399861e+05, 9.93718614e+04, 9.73844229e+04,\n       9.54367369e+04, 9.35280024e+04, 9.16574381e+04, 8.98242822e+04,\n       8.80277978e+04, 8.62672343e+04, 8.45418895e+04, 8.28510467e+04,\n       8.11940301e+04, 7.95701572e+04, 7.79787507e+04, 7.64191725e+04,\n       7.48907821e+04, 7.33929679e+04, 7.19251095e+04, 7.04866085e+04,\n       6.90768754e+04, 6.76953439e+04, 6.63414373e+04, 6.50146096e+04,\n       6.37143124e+04, 6.24400302e+04, 6.11912339e+04, 5.99674066e+04,\n       5.87680632e+04, 5.75927040e+04, 5.64408431e+04, 5.53120324e+04,\n       5.42057969e+04, 5.31216867e+04, 5.20592499e+04, 5.10180617e+04,\n       4.99977036e+04, 4.89977502e+04, 4.80177967e+04, 4.70574362e+04,\n       4.61162816e+04, 4.51939536e+04, 4.42900780e+04, 4.34042814e+04,\n       4.25362039e+04, 4.16854845e+04, 4.08517805e+04, 4.00347497e+04,\n       3.92340619e+04, 3.84493749e+04, 3.76803907e+04, 3.69267816e+04,\n       3.61882491e+04, 3.54644845e+04, 3.47551877e+04, 3.40600787e+04,\n       3.33788743e+04, 3.27112966e+04, 3.20570781e+04, 3.14159379e+04,\n       3.07876245e+04, 3.01718746e+04, 2.95684372e+04, 2.89770624e+04,\n       2.83975154e+04, 2.78295624e+04, 2.72729692e+04, 2.67275151e+04,\n       2.61929688e+04, 2.56691092e+04, 2.51557338e+04, 2.46526253e+04,\n       2.41595775e+04, 2.36763903e+04, 2.32028591e+04, 2.27387972e+04,\n       2.22840154e+04, 2.18383281e+04, 2.14015626e+04, 2.09735315e+04,\n       2.05540622e+04, 2.01429841e+04, 1.97401252e+04, 1.93453283e+04,\n       1.89584219e+04, 1.85792504e+04, 1.82076722e+04, 1.78435153e+04,\n       1.74866404e+04, 1.71369066e+04, 1.67941723e+04, 1.64582808e+04,\n       1.61291096e+04, 1.58065313e+04, 1.54904063e+04, 1.51805939e+04,\n       1.48769846e+04, 1.45794376e+04, 1.42878438e+04, 1.40020936e+04,\n       1.37220471e+04, 1.34476092e+04, 1.31786561e+04, 1.29150783e+04,\n       1.26567813e+04, 1.24036408e+04, 1.21555623e+04, 1.19124533e+04,\n       1.16742034e+04, 1.14407189e+04, 1.12119062e+04, 1.09876720e+04,\n       1.07679220e+04, 1.05525625e+04, 1.03415156e+04, 1.01346874e+04,\n       9.93200000e+03, 9.73335954e+03, 9.53868754e+03, 9.34790629e+03,\n       9.16095323e+03, 8.97773424e+03, 8.79818754e+03, 8.62221874e+03,\n       8.44978106e+03, 8.28078112e+03, 8.11517196e+03, 7.95287495e+03,\n       7.79381242e+03, 7.63793742e+03, 7.48517174e+03, 7.33546863e+03,\n       7.18876568e+03, 7.04498432e+03, 6.90407822e+03, 6.76600000e+03,\n       6.63068745e+03, 6.49807818e+03, 6.36810930e+03, 6.24074995e+03,\n       6.11593754e+03, 5.99362495e+03, 5.87375008e+03, 5.75628126e+03,\n       5.64115626e+03, 5.52832814e+03, 5.41776559e+03, 5.30940618e+03,\n       5.20321881e+03, 5.09915620e+03, 4.99717180e+03, 4.89723432e+03,\n       4.79929682e+03, 4.70331245e+03, 4.60925005e+03, 4.51706254e+03,\n       4.42671865e+03, 4.33818741e+03, 4.25142188e+03, 4.16639052e+03,\n       4.08306245e+03, 4.00140625e+03, 3.92137501e+03, 3.84295316e+03,\n       3.76609373e+03, 3.69076564e+03, 3.61695314e+03, 3.54460943e+03,\n       3.47371876e+03, 3.40424999e+03, 3.33617191e+03, 3.26945317e+03,\n       3.20406258e+03, 3.13998439e+03, 3.07718751e+03, 3.01564056e+03,\n       2.95532807e+03, 2.89621874e+03, 2.83829685e+03, 2.78153123e+03,\n       2.72590627e+03, 2.67139065e+03, 2.61796877e+03, 2.56560938e+03,\n       2.51429692e+03, 2.46401562e+03, 2.41473435e+03, 2.36643751e+03,\n       2.31910942e+03, 2.27273437e+03, 2.22728130e+03, 2.18273441e+03,\n       2.13907807e+03, 2.09629685e+03, 2.05437497e+03, 2.01328128e+03,\n       1.97301565e+03, 1.93356252e+03, 1.89489063e+03, 1.85700000e+03,\n       1.81985940e+03, 1.78346874e+03, 1.74779690e+03, 1.71284376e+03,\n       1.67859376e+03, 1.64501565e+03, 1.61210941e+03, 1.57987500e+03,\n       1.54828122e+03, 1.51731251e+03, 1.48696873e+03, 1.45723437e+03,\n       1.42809375e+03, 1.39953126e+03, 1.37154689e+03, 1.34410937e+03,\n       1.31723437e+03, 1.29089063e+03, 1.26507811e+03, 1.23978123e+03,\n       1.21498436e+03, 1.19068751e+03, 1.16687499e+03, 1.14353126e+03,\n       1.12065623e+03, 1.09824997e+03, 1.07628127e+03, 1.05474997e+03,\n       1.03365625e+03, 1.01298439e+03, 9.92718742e+02, 9.72859381e+02,\n       9.53406262e+02, 9.34343754e+02, 9.15656254e+02, 8.97343754e+02,\n       8.79390627e+02, 8.61796887e+02, 8.44562498e+02, 8.27671885e+02,\n       8.11124990e+02, 7.94906244e+02, 7.79015645e+02, 7.63437497e+02,\n       7.48171855e+02, 7.33203118e+02, 7.18531249e+02, 7.04156255e+02,\n       6.90078121e+02, 6.76281261e+02, 6.62750000e+02, 6.49500000e+02,\n       6.36515637e+02, 6.23781262e+02, 6.11312497e+02, 5.99093743e+02,\n       5.87109365e+02, 5.75374986e+02, 5.63874986e+02, 5.52593742e+02,\n       5.41546887e+02, 5.30718764e+02, 5.20109363e+02, 5.09703131e+02,\n       4.99515625e+02, 4.89531249e+02, 4.79734383e+02, 4.70140621e+02,\n       4.60734383e+02, 4.51515625e+02, 4.42484375e+02, 4.33640620e+02,\n       4.24968749e+02, 4.16468749e+02, 4.08140620e+02, 3.99984375e+02,\n       3.91984375e+02, 3.84140620e+02, 3.76453122e+02, 3.68921867e+02,\n       3.61546872e+02, 3.54312494e+02, 3.47218749e+02, 3.40281249e+02,\n       3.33468749e+02, 3.26796872e+02, 3.20265625e+02, 3.13859381e+02,\n       3.07578128e+02, 3.01421878e+02, 2.95390631e+02, 2.89484375e+02,\n       2.83687493e+02, 2.78015625e+02, 2.72453121e+02, 2.67000000e+02,\n       2.61656248e+02, 2.56421878e+02, 2.51296878e+02, 2.46265625e+02,\n       2.41343748e+02, 2.36515624e+02, 2.31781248e+02, 2.27140624e+02,\n       2.22593748e+02, 2.18140624e+02, 2.13781248e+02, 2.09500000e+02,\n       2.05312500e+02, 2.01203129e+02, 1.97171879e+02, 1.93234374e+02,\n       1.89375000e+02, 1.85593747e+02, 1.81875000e+02, 1.78234374e+02,\n       1.74671874e+02, 1.71171874e+02, 1.67750000e+02, 1.64390624e+02,\n       1.61109374e+02, 1.57890624e+02, 1.54734374e+02, 1.51640624e+02,\n       1.48609374e+02, 1.45640624e+02, 1.42734374e+02, 1.39875000e+02,\n       1.37078124e+02, 1.34343746e+02, 1.31656246e+02, 1.29015624e+02,\n       1.26437500e+02, 1.23906250e+02, 1.21421874e+02, 1.19000000e+02,\n       1.16625000e+02, 1.14296874e+02, 1.12015624e+02, 1.09781250e+02,\n       1.07578124e+02, 1.05421874e+02, 1.03312500e+02, 1.01250000e+02,\n       9.92187500e+01, 9.72343737e+01, 9.52968737e+01, 9.33906237e+01,\n       9.15156237e+01, 8.96875000e+01, 8.78906236e+01, 8.61250000e+01,\n       8.44062500e+01, 8.27187500e+01, 8.10625000e+01, 7.94375000e+01,\n       7.78437500e+01, 7.62812500e+01, 7.47500000e+01, 7.32500000e+01,\n       7.17812500e+01, 7.03437500e+01, 6.89375000e+01, 6.75625000e+01,\n       6.62187500e+01, 6.48906231e+01, 6.35937500e+01, 6.23281250e+01,\n       6.10781250e+01, 5.98593750e+01, 5.86562500e+01, 5.74843750e+01,\n       5.63281250e+01, 5.52031250e+01, 5.40937500e+01, 5.30156250e+01,\n       5.19531250e+01, 5.09062500e+01, 4.98906250e+01, 4.88906250e+01,\n       4.79062500e+01, 4.69531250e+01, 4.60156250e+01, 4.50937500e+01,\n       4.41875000e+01, 4.32968750e+01, 4.24375000e+01, 4.15937500e+01,\n       4.07656250e+01, 3.99531250e+01, 3.91562500e+01, 3.83750000e+01,\n       3.76093750e+01, 3.68593750e+01, 3.61250000e+01, 3.54062500e+01,\n       3.47031250e+01, 3.40156250e+01, 3.33281250e+01, 3.26562500e+01,\n       3.20000000e+01, 3.13593750e+01, 3.07343750e+01, 3.01250000e+01,\n       2.95156250e+01, 2.89218750e+01, 2.83437500e+01, 2.77812500e+01,\n       2.72187500e+01, 2.66718750e+01, 2.61406250e+01, 2.56250000e+01,\n       2.51093750e+01, 2.46093750e+01, 2.41250000e+01, 2.36406250e+01,\n       2.31718750e+01, 2.27031250e+01, 2.22500000e+01, 2.18125000e+01,\n       2.13750000e+01, 2.09531250e+01, 2.05312500e+01, 2.01250000e+01,\n       1.97187500e+01, 1.93281250e+01, 1.89375000e+01, 1.85625000e+01,\n       1.81875000e+01, 1.78281250e+01, 1.74687500e+01, 1.71250000e+01,\n       1.67812500e+01, 1.64531250e+01, 1.61250000e+01, 1.57968750e+01,\n       1.54843750e+01, 1.51718750e+01, 1.48750000e+01, 1.45781250e+01,\n       1.42812500e+01, 1.40000000e+01, 1.37187500e+01, 1.34375000e+01,\n       1.31718750e+01, 1.29062500e+01, 1.26406250e+01, 1.23906250e+01,\n       1.21406250e+01, 1.18906250e+01, 1.16562500e+01, 1.14218750e+01,\n       1.11875000e+01, 1.09687500e+01, 1.07500000e+01, 1.05312500e+01,\n       1.03281250e+01, 1.01250000e+01, 9.92187500e+00, 9.71875000e+00,\n       9.53125000e+00, 9.34375000e+00, 9.15625000e+00, 8.96875000e+00,\n       8.79687500e+00, 8.62500000e+00, 8.45312500e+00, 8.28125000e+00,\n       8.10937500e+00, 7.95312500e+00, 7.79687500e+00, 7.64062500e+00,\n       7.48437500e+00, 7.32812500e+00, 7.18750000e+00, 7.04687500e+00,\n       6.90625000e+00, 6.76562500e+00, 6.62500000e+00, 6.50000000e+00,\n       6.37500000e+00, 6.25000000e+00, 6.12500000e+00, 6.00000000e+00,\n       5.87500000e+00, 5.75000000e+00, 5.64062500e+00, 5.53125000e+00,\n       5.42187500e+00, 5.31250000e+00, 5.20312500e+00, 5.09375000e+00,\n       4.98437500e+00, 4.89062500e+00, 4.79687500e+00, 4.70312500e+00,\n       4.60937500e+00, 4.51562500e+00, 4.42187500e+00, 4.32812500e+00,\n       4.23437500e+00, 4.15625000e+00, 4.07812500e+00, 4.00000000e+00,\n       3.92187500e+00, 3.84375000e+00, 3.76562500e+00, 3.68750000e+00,\n       3.60937500e+00, 3.53125000e+00, 3.45312500e+00, 3.39062500e+00,\n       3.32812500e+00, 3.26562500e+00, 3.20312500e+00, 3.14062500e+00,\n       3.07812500e+00, 3.01562500e+00, 2.95312500e+00, 2.89062500e+00,\n       2.82812500e+00, 2.76562500e+00, 2.70312500e+00, 2.65625000e+00,\n       2.60937500e+00, 2.56250000e+00, 2.51562500e+00, 2.46875000e+00,\n       2.42187500e+00, 2.37500000e+00, 2.32812500e+00, 2.28125000e+00,\n       2.23437500e+00, 2.18750000e+00, 2.14062500e+00, 2.09375000e+00,\n       2.04687500e+00, 2.00000000e+00, 1.95312500e+00, 1.90625000e+00,\n       1.87500000e+00, 1.84375000e+00, 1.81250000e+00, 1.78125000e+00,\n       1.75000000e+00, 1.71875000e+00, 1.68750000e+00, 1.65625000e+00,\n       1.62500000e+00, 1.59375000e+00, 1.56250000e+00, 1.53125000e+00,\n       1.50000000e+00, 1.46875000e+00, 1.43750000e+00, 1.40625000e+00,\n       1.37500000e+00, 1.34375000e+00, 1.31250000e+00, 1.28125000e+00,\n       1.25000000e+00, 1.21875000e+00, 1.18750000e+00, 1.15625000e+00,\n       1.14062500e+00, 1.12500000e+00, 1.10937500e+00, 1.09375000e+00,\n       1.07812500e+00, 1.06250000e+00, 1.04687500e+00, 1.03125000e+00,\n       1.01562500e+00, 1.00000000e+00, 9.84375000e-01, 9.68750000e-01,\n       9.53125000e-01, 9.37500000e-01, 9.21875000e-01, 9.06250000e-01,\n       8.90625000e-01, 8.75000000e-01, 8.59375000e-01, 8.43750000e-01,\n       8.28125000e-01, 8.12500000e-01, 7.96875000e-01, 7.81250000e-01,\n       7.65625000e-01, 7.50000000e-01, 7.34375000e-01, 7.18750000e-01,\n       7.03125000e-01, 6.87500000e-01, 6.71875000e-01, 6.56250000e-01,\n       6.40625000e-01, 6.25000000e-01, 6.09375000e-01, 5.93750000e-01,\n       5.78125000e-01, 5.62500000e-01, 5.46875000e-01, 5.31250000e-01,\n       5.15625000e-01, 5.00000000e-01, 4.84375000e-01, 4.68750000e-01,\n       4.53125000e-01, 4.37500000e-01, 4.21875000e-01, 4.06250000e-01,\n       3.90625000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01,\n       3.75000000e-01, 3.75000000e-01, 3.75000000e-01, 3.75000000e-01])"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700278372047,"execution_millis":7,"deepnote_to_be_reexecuted":false,"cell_id":"86688d7a258e47659f62b3c62f9ffc78","deepnote_cell_type":"code"},"source":"train_Y[:5000]","block_group":"7661a02e256047048a15ec3373295ab9","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"array([257274., 247827., 242481., ..., 310526., 332580., 354238.])"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700278374770,"execution_millis":1240,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":50,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"e280b9f2ac70461dbbb9170c55a9b2bb","deepnote_cell_type":"code"},"source":"train_predict = model3.predict(train_X[:5000, :, :])\npd.DataFrame(train_predict)","block_group":"484e9f9d06574cdeb6d6fe7ec2ed1402","execution_count":null,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 1s 7ms/step\n","output_type":"stream"},{"output_type":"execute_result","execution_count":42,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":1,"row_count":5000,"columns":[{"name":0,"dtype":"float32","stats":{"unique_count":1,"nan_count":0,"min":"257273.625","max":"257273.625","histogram":[{"bin_start":257273.125,"bin_end":257273.21875,"count":0},{"bin_start":257273.21875,"bin_end":257273.328125,"count":0},{"bin_start":257273.328125,"bin_end":257273.421875,"count":0},{"bin_start":257273.421875,"bin_end":257273.53125,"count":0},{"bin_start":257273.53125,"bin_end":257273.625,"count":0},{"bin_start":257273.625,"bin_end":257273.71875,"count":5000},{"bin_start":257273.71875,"bin_end":257273.828125,"count":0},{"bin_start":257273.828125,"bin_end":257273.921875,"count":0},{"bin_start":257273.921875,"bin_end":257274.03125,"count":0},{"bin_start":257274.03125,"bin_end":257274.125,"count":0}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"0":257273.625,"_deepnote_index_column":0},{"0":257273.625,"_deepnote_index_column":1},{"0":257273.625,"_deepnote_index_column":2},{"0":257273.625,"_deepnote_index_column":3},{"0":257273.625,"_deepnote_index_column":4},{"0":257273.625,"_deepnote_index_column":5},{"0":257273.625,"_deepnote_index_column":6},{"0":257273.625,"_deepnote_index_column":7},{"0":257273.625,"_deepnote_index_column":8},{"0":257273.625,"_deepnote_index_column":9},{"0":257273.625,"_deepnote_index_column":10},{"0":257273.625,"_deepnote_index_column":11},{"0":257273.625,"_deepnote_index_column":12},{"0":257273.625,"_deepnote_index_column":13},{"0":257273.625,"_deepnote_index_column":14},{"0":257273.625,"_deepnote_index_column":15},{"0":257273.625,"_deepnote_index_column":16},{"0":257273.625,"_deepnote_index_column":17},{"0":257273.625,"_deepnote_index_column":18},{"0":257273.625,"_deepnote_index_column":19},{"0":257273.625,"_deepnote_index_column":20},{"0":257273.625,"_deepnote_index_column":21},{"0":257273.625,"_deepnote_index_column":22},{"0":257273.625,"_deepnote_index_column":23},{"0":257273.625,"_deepnote_index_column":24},{"0":257273.625,"_deepnote_index_column":25},{"0":257273.625,"_deepnote_index_column":26},{"0":257273.625,"_deepnote_index_column":27},{"0":257273.625,"_deepnote_index_column":28},{"0":257273.625,"_deepnote_index_column":29},{"0":257273.625,"_deepnote_index_column":30},{"0":257273.625,"_deepnote_index_column":31},{"0":257273.625,"_deepnote_index_column":32},{"0":257273.625,"_deepnote_index_column":33},{"0":257273.625,"_deepnote_index_column":34},{"0":257273.625,"_deepnote_index_column":35},{"0":257273.625,"_deepnote_index_column":36},{"0":257273.625,"_deepnote_index_column":37},{"0":257273.625,"_deepnote_index_column":38},{"0":257273.625,"_deepnote_index_column":39},{"0":257273.625,"_deepnote_index_column":40},{"0":257273.625,"_deepnote_index_column":41},{"0":257273.625,"_deepnote_index_column":42},{"0":257273.625,"_deepnote_index_column":43},{"0":257273.625,"_deepnote_index_column":44},{"0":257273.625,"_deepnote_index_column":45},{"0":257273.625,"_deepnote_index_column":46},{"0":257273.625,"_deepnote_index_column":47},{"0":257273.625,"_deepnote_index_column":48},{"0":257273.625,"_deepnote_index_column":49}]},"text/plain":"               0\n0     257273.625\n1     257273.625\n2     257273.625\n3     257273.625\n4     257273.625\n...          ...\n4995  257273.625\n4996  257273.625\n4997  257273.625\n4998  257273.625\n4999  257273.625\n\n[5000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>257273.625</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>257273.625</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>257273.625</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>257273.625</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>257273.625</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>257273.625</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>257273.625</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>257273.625</td>\n    </tr>\n    <tr>\n      <th>4998</th>\n      <td>257273.625</td>\n    </tr>\n    <tr>\n      <th>4999</th>\n      <td>257273.625</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700271568334,"execution_millis":3213,"deepnote_to_be_reexecuted":false,"cell_id":"6fbe1cfd66d34bba9684716359bd5007","deepnote_cell_type":"code"},"source":"import matplotlib.pyplot as plt\nplt.hist(train_Y)","block_group":"1b021d1ef9054dd2bccb32361f8a274e","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":63,"data":{"text/plain":"(array([  486., 14066., 17391., 13258.,  4917.,  2628.,  1699.,   832.,\n          242.,    28.]),\n array([14104.4425    , 17606.08991667, 21107.73733333, 24609.38475   ,\n        28111.03216667, 31612.67958333, 35114.327     , 38615.97441667,\n        42117.62183333, 45619.26925   , 49120.91666667]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{"image/png":{"width":580,"height":413}},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1700263625861,"execution_millis":24299,"deepnote_to_be_reexecuted":true,"cell_id":"ec59147a09644d2888089b43bdef2b8f","deepnote_cell_type":"code"},"source":"# Make predictions\ntrain_predict = model.predict(train_X)\ntest_predict = model.predict(test_X)\n\n# Invert predictions\ntrain_Y, test_Y = Y[0:train_size], Y[train_size:len(Y)]\ntrain_predict = scaler.inverse_transform(train_predict)\ntrain_Y = scaler.inverse_transform([train_Y])\ntest_predict = scaler.inverse_transform(test_predict)\ntest_Y = scaler.inverse_transform([test_Y])\n\ndef mse(predicted, actual):\n    return np.mean((predicted - actual) ** 2)\n\n# Calculate root mean squared error\ntrain_score = np.sqrt(mse(train_Y[0], train_predict[:,0]))\nprint('Train Score: %.2f RMSE' % (train_score))\ntest_score = np.sqrt(mse(test_Y[0], test_predict[:,0]))\nprint('Test Score: %.2f RMSE' % (test_score))","block_group":"297c5cad3b0443ed83f607c7a8c9b114","execution_count":null,"outputs":[{"name":"stdout","text":"1150/1752 [==================>...........] - ETA: 10s","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_X)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Invert predictions\u001b[39;00m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/keras/engine/training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2255\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"cell_id":"e2d29bcab7f94fe3a775bc9657124f05","deepnote_cell_type":"code"},"source":"# Plotting baseline and predictions\nplt.figure(figsize=(10,6))\nplt.plot(scaler.inverse_transform(scaled_data))\nplt.plot(np.concatenate((train_predict, test_predict)))\nplt.show()","block_group":"453ac8f6691f4d7caa7aadbf847bec4e","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b82b9643-cfd7-4eed-98d3-bc210272c836' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"ba863154505c4e2480dd5c7693a20fb2","deepnote_execution_queue":[]}}